{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Investigation\n",
    "\n",
    "#### The following notebook is how we downloaded, cleaned and optimised our data before choosing the appropriate model to use in our Application.\n",
    "\n",
    "### Downloading and Cleaning\n",
    "The final merged dataset was downloaded from brightspace and investigated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_merged_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "This dataset has 78 keys that we can use for prediction. However, when we are calculating predictions for the user in the Application, we will be using the open weather API, thus we need to make sure explanatory variables we choose from the dataset are highly comparable to explanatory variables from the open weather API.\n",
    "\n",
    "Of the 78 possible variables, many are very different to the variables in our API. The mismatch between the two datasets falls into 3 main categories:\n",
    "- (i)               Too granular for API: Information like is_renting or is_returning is very in depth information that is not provided by even v3 of the API, although it would be useful if it was.\n",
    "- (ii)            Broad information: Information like year, address, etc. is too broad and although we can generate corresponding information it is encoded better by other variables.\n",
    "- (iii)            Irrelevant information / Not Provided by API: Most of the information is completely irrelevant and correspondingly not provided by the API. Over 60 metrics are indicators for soil, earth, grass, etc. quality and temperature. This has not logical link to the number of bikes available or not.\n",
    "\n",
    "In the end we identified 5 explanatory variables that are different enough to include but important when discussing the probability of bike availability for each station.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An average of min and max is used to a more comparable value to Open Weather API's temerature\n",
    "# The same is true for humidity and pressure\n",
    "data[\"temperature\"] = (data[\"max_air_temperature_celsius\"] + data[\"min_air_temperature_celsius\"]) / 2\n",
    "data[\"humidity\"] = (data[\"max_relative_humidity_percent\"] + data[\"min_relative_humidity_percent\"]) / 2\n",
    "data[\"pressure\"] = (data[\"max_barometric_pressure_hpa\"] + data[\"min_barometric_pressure_hpa\"]) / 2\n",
    "\n",
    "data = data[[\"num_bikes_available\",\"station_id\",\"year\", \"month\", \"day\", \"hour\", \"temperature\", \"humidity\", \"pressure\"]]\n",
    "\n",
    "# Time is taken in 5m intervals in the data set but our API can only do 1-3 hour blocks depending on the call\n",
    "# Thus taking by hour will lead to hundreds of datapoints with the same time stamp even though they are actually different on a minute scale\n",
    "# This can introduce bias into our mode so we group by hours and find the means for more accurate predictions down the line\n",
    "data = data.groupby([\"station_id\", \"year\", \"month\", \"day\", \"hour\"]).mean().reset_index()\n",
    "data[\"num_bikes_available\"] = round(data[\"num_bikes_available\"])\n",
    "\n",
    "# From the time data we identify the day *\"Monday\", \"Tuesday\" etc.) so that we can then create a binary variable if it is the weekend or not\n",
    "# Further information is available in the report\n",
    "data[\"day_name\"] = pd.to_datetime(data[[\"year\", \"month\", \"day\"]]).dt.day_name()\n",
    "data[\"is_weekday\"] = data[\"day_name\"].apply(lambda x: 0 if x == \"Sunday\" or x==\"Saturday\" else 1)\n",
    "\n",
    "# The final dataset\n",
    "data = data[[\"num_bikes_available\",\"station_id\", \"is_weekday\", \"hour\", \"temperature\", \"humidity\", \"pressure\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_bikes_available</th>\n",
       "      <th>station_id</th>\n",
       "      <th>is_weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.890000</td>\n",
       "      <td>84.475000</td>\n",
       "      <td>1002.422500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12.235000</td>\n",
       "      <td>87.950000</td>\n",
       "      <td>1000.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>11.263333</td>\n",
       "      <td>89.583333</td>\n",
       "      <td>1000.108333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11.236667</td>\n",
       "      <td>89.633333</td>\n",
       "      <td>1000.151667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>11.680000</td>\n",
       "      <td>86.300000</td>\n",
       "      <td>1000.325000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_bikes_available  station_id  is_weekday  hour  temperature   humidity  \\\n",
       "0                 20.0           1           0     0    13.890000  84.475000   \n",
       "1                 20.0           1           0     5    12.235000  87.950000   \n",
       "2                 22.0           1           0     6    11.263333  89.583333   \n",
       "3                 25.0           1           0     7    11.236667  89.633333   \n",
       "4                 30.0           1           0     8    11.680000  86.300000   \n",
       "\n",
       "      pressure  \n",
       "0  1002.422500  \n",
       "1  1000.200000  \n",
       "2  1000.108333  \n",
       "3  1000.151667  \n",
       "4  1000.325000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning\n",
    "#### Model selection\n",
    "There are many models we can choose for the machine learning portion of this application, of different flexibility. We shall use 5 of the smallest as SVMs or Neural networks will make .pkl files that are too large for our EC2. For Random forrest we choose number of estimators of 50 from advice from stack overflow (https://stackoverflow.com/questions/60768008/how-to-choose-n-estimators-in-randomforestclassifier), with the same logic, we choose 5  neigbors for KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=50, random_state=42),\n",
    "    \"KNN\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Our metrics are a mixture of standard regression metrics MAE and R^2 and precision / recall as suggested by our lecture notes\n",
    "metrics = [\"mae\", \"r2\", \"precision\", \"recall\"]\n",
    "model_performance = {model: {m: [] for m in metrics} for model in models}\n",
    "\n",
    "unique_ids = data[\"station_id\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "##### MAE (Mean Absolute Error):\n",
    "- Represents the average of the absolute errors between predicted and actual values.\n",
    "- A lower MAE is better as it indicates that the model's predictions are closer to the actual values.\n",
    "\n",
    "##### R² (R-squared):\n",
    "- Indicates how well the model's predictions match the actual data.\n",
    "- An R² closer to 1 indicates a better fit, with 0 implying no explanatory power and negative values suggesting worse performance than a simple mean model.\n",
    "\n",
    "##### Precision:\n",
    "- The proportion of true positive predictions out of all positive predictions made by the model.\n",
    "- Higher precision indicates fewer false positives, meaning the model is good at identifying only relevant predictions.\n",
    "\n",
    "##### Recall:\n",
    "- The proportion of true positive predictions out of all actual positive instances.\n",
    "- Higher recall means fewer false negatives, indicating that the model is good at identifying all positive instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average Performance Across All Stations:\n",
      " Model: LinearRegression\n",
      "  MAE      : 5.6490\n",
      "  R2       : 0.1550\n",
      "  PRECISION: 0.9013\n",
      "  RECALL   : 0.9793\n",
      " Model: DecisionTree\n",
      "  MAE      : 3.5598\n",
      "  R2       : 0.3448\n",
      "  PRECISION: 0.9334\n",
      "  RECALL   : 0.9368\n",
      " Model: RandomForest\n",
      "  MAE      : 3.2262\n",
      "  R2       : 0.6248\n",
      "  PRECISION: 0.9014\n",
      "  RECALL   : 0.9825\n",
      " Model: KNN\n",
      "  MAE      : 4.0989\n",
      "  R2       : 0.4495\n",
      "  PRECISION: 0.9044\n",
      "  RECALL   : 0.9816\n",
      " Model: GradientBoosting\n",
      "  MAE      : 3.8314\n",
      "  R2       : 0.5351\n",
      "  PRECISION: 0.9030\n",
      "  RECALL   : 0.9792\n"
     ]
    }
   ],
   "source": [
    "for station_id in unique_ids:\n",
    "    \"\"\"\n",
    "    For evaluation, it was decided to train and test separate models for each unique station. \n",
    "    For each station, relevant features were extracted and data was partitioned with a 70-30 train-test split.\n",
    "    \"\"\"\n",
    "    id_data = data[data[\"station_id\"] == station_id]\n",
    "    \n",
    "    X = id_data[[\"is_weekday\", \"hour\", \"temperature\", \"humidity\", \"pressure\"]]\n",
    "    y = id_data[\"num_bikes_available\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        y_test_bin = (y_test > 0).astype(int)\n",
    "        y_pred_bin = (y_pred > 0).astype(int)\n",
    "\n",
    "        precision = precision_score(y_test_bin, y_pred_bin, zero_division=0)\n",
    "        recall = recall_score(y_test_bin, y_pred_bin, zero_division=0)\n",
    "\n",
    "        model_performance[name][\"mae\"].append(mae)\n",
    "        model_performance[name][\"r2\"].append(r2)\n",
    "        model_performance[name][\"precision\"].append(precision)\n",
    "        model_performance[name][\"recall\"].append(recall)\n",
    "\n",
    "# Output average performance\n",
    "print(\" Average Performance Across All Stations:\")\n",
    "for name, scores in model_performance.items():\n",
    "    print(f\" Model: {name}\")\n",
    "    for metric in metrics:\n",
    "        avg_score = np.mean(scores[metric])\n",
    "        print(f\"  {metric.upper():<9}: {avg_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Analysis\n",
    "##### Linear Regression\n",
    "- MAE is relatively high, indicating that the model's predictions are off by an average of ~5.65 units.\n",
    "- R² is very low (0.155), meaning the model is explaining very little of the variance in the data.\n",
    "- Precision and Recall are decent, but the low R² suggests that this model is not a great fit for the data. The high Recall is a positive, indicating the model does a good job of identifying most positive instances, but the MAE and low R² show that it's not very accurate.\n",
    "\n",
    "##### Decision Tree\n",
    "- The MAE is lower than Linear Regression, indicating the model is predicting values more accurately.\n",
    "- The R² is higher than Linear Regression, but still not great. It shows that the model explains about 34% of the variance in the data.\n",
    "- Precision and Recall are both higher than Linear Regression, meaning this model is better at identifying relevant instances (higher precision) and missing fewer relevant predictions (higher recall).\n",
    "\n",
    "##### Random Forrest\n",
    "- MAE is lower than both Linear Regression and Decision Tree, showing better predictive accuracy.\n",
    "- R² is quite strong at 0.6248, indicating that this model is explaining more than 60% of the variance in the data. This is a significant improvement.\n",
    "- Precision and Recall are comparable to Decision Tree, with Recall being exceptionally high at 0.9825 (almost perfect at identifying relevant instances).\n",
    "- This model is performing very well across multiple metrics, particularly in terms of R², which shows it’s a much better fit than simpler models.\n",
    "\n",
    "##### KNN\n",
    "- The MAE is higher than Random Forest and Decision Tree, but lower than Linear Regression. It’s not the best in terms of accuracy.\n",
    "- R² is also weaker than Random Forest, but still explains about 45% of the variance, which is decent.\n",
    "- Precision and Recall are both high, but slightly worse than Decision Tree and Random Forest. Still, the model identifies most positive instances, with only a small drop in Precision compared to others.\n",
    "- While decent overall, KNN doesn't perform as well as Random Forest in terms of R².\n",
    "\n",
    "##### Gradient Boosting\n",
    "- The MAE is similar to KNN, but higher than Random Forest and Decision Tree.\n",
    "- The R² (0.5351) is better than Decision Tree and KNN, but not as good as Random Forest.\n",
    "- Precision and Recall are strong, with Recall close to the highest (0.9792). However, its Precision is slightly lower than Decision Tree.\n",
    "- Gradient Boosting performs better than Decision Tree but still lags behind Random Forest in terms of both R² and MAE.\n",
    "\n",
    "##### Summary\n",
    "- Random Forrest is the best overall with the lowest MAE, highest  R² and very good Recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model\n",
    "Using Random Forrest Regressor, we will now make a pkl file to predict bike availability for each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to avail_station_1.pkl for station 1\n",
      "Model saved to avail_station_2.pkl for station 2\n",
      "Model saved to avail_station_3.pkl for station 3\n",
      "Model saved to avail_station_4.pkl for station 4\n",
      "Model saved to avail_station_5.pkl for station 5\n",
      "Model saved to avail_station_6.pkl for station 6\n",
      "Model saved to avail_station_7.pkl for station 7\n",
      "Model saved to avail_station_8.pkl for station 8\n",
      "Model saved to avail_station_9.pkl for station 9\n",
      "Model saved to avail_station_10.pkl for station 10\n",
      "Model saved to avail_station_11.pkl for station 11\n",
      "Model saved to avail_station_12.pkl for station 12\n",
      "Model saved to avail_station_13.pkl for station 13\n",
      "Model saved to avail_station_14.pkl for station 14\n",
      "Model saved to avail_station_15.pkl for station 15\n",
      "Model saved to avail_station_16.pkl for station 16\n",
      "Model saved to avail_station_17.pkl for station 17\n",
      "Model saved to avail_station_18.pkl for station 18\n",
      "Model saved to avail_station_19.pkl for station 19\n",
      "Model saved to avail_station_20.pkl for station 20\n",
      "Model saved to avail_station_21.pkl for station 21\n",
      "Model saved to avail_station_22.pkl for station 22\n",
      "Model saved to avail_station_23.pkl for station 23\n",
      "Model saved to avail_station_24.pkl for station 24\n",
      "Model saved to avail_station_25.pkl for station 25\n",
      "Model saved to avail_station_26.pkl for station 26\n",
      "Model saved to avail_station_27.pkl for station 27\n",
      "Model saved to avail_station_28.pkl for station 28\n",
      "Model saved to avail_station_29.pkl for station 29\n",
      "Model saved to avail_station_30.pkl for station 30\n",
      "Model saved to avail_station_31.pkl for station 31\n",
      "Model saved to avail_station_32.pkl for station 32\n",
      "Model saved to avail_station_33.pkl for station 33\n",
      "Model saved to avail_station_34.pkl for station 34\n",
      "Model saved to avail_station_35.pkl for station 35\n",
      "Model saved to avail_station_36.pkl for station 36\n",
      "Model saved to avail_station_37.pkl for station 37\n",
      "Model saved to avail_station_38.pkl for station 38\n",
      "Model saved to avail_station_39.pkl for station 39\n",
      "Model saved to avail_station_40.pkl for station 40\n",
      "Model saved to avail_station_41.pkl for station 41\n",
      "Model saved to avail_station_42.pkl for station 42\n",
      "Model saved to avail_station_43.pkl for station 43\n",
      "Model saved to avail_station_44.pkl for station 44\n",
      "Model saved to avail_station_45.pkl for station 45\n",
      "Model saved to avail_station_47.pkl for station 47\n",
      "Model saved to avail_station_48.pkl for station 48\n",
      "Model saved to avail_station_49.pkl for station 49\n",
      "Model saved to avail_station_50.pkl for station 50\n",
      "Model saved to avail_station_51.pkl for station 51\n",
      "Model saved to avail_station_52.pkl for station 52\n",
      "Model saved to avail_station_53.pkl for station 53\n",
      "Model saved to avail_station_54.pkl for station 54\n",
      "Model saved to avail_station_55.pkl for station 55\n",
      "Model saved to avail_station_56.pkl for station 56\n",
      "Model saved to avail_station_57.pkl for station 57\n",
      "Model saved to avail_station_58.pkl for station 58\n",
      "Model saved to avail_station_59.pkl for station 59\n",
      "Model saved to avail_station_60.pkl for station 60\n",
      "Model saved to avail_station_61.pkl for station 61\n",
      "Model saved to avail_station_62.pkl for station 62\n",
      "Model saved to avail_station_63.pkl for station 63\n",
      "Model saved to avail_station_64.pkl for station 64\n",
      "Model saved to avail_station_65.pkl for station 65\n",
      "Model saved to avail_station_66.pkl for station 66\n",
      "Model saved to avail_station_67.pkl for station 67\n",
      "Model saved to avail_station_68.pkl for station 68\n",
      "Model saved to avail_station_69.pkl for station 69\n",
      "Model saved to avail_station_70.pkl for station 70\n",
      "Model saved to avail_station_71.pkl for station 71\n",
      "Model saved to avail_station_72.pkl for station 72\n",
      "Model saved to avail_station_73.pkl for station 73\n",
      "Model saved to avail_station_74.pkl for station 74\n",
      "Model saved to avail_station_75.pkl for station 75\n",
      "Model saved to avail_station_76.pkl for station 76\n",
      "Model saved to avail_station_77.pkl for station 77\n",
      "Model saved to avail_station_78.pkl for station 78\n",
      "Model saved to avail_station_79.pkl for station 79\n",
      "Model saved to avail_station_80.pkl for station 80\n",
      "Model saved to avail_station_82.pkl for station 82\n",
      "Model saved to avail_station_83.pkl for station 83\n",
      "Model saved to avail_station_84.pkl for station 84\n",
      "Model saved to avail_station_85.pkl for station 85\n",
      "Model saved to avail_station_86.pkl for station 86\n",
      "Model saved to avail_station_87.pkl for station 87\n",
      "Model saved to avail_station_88.pkl for station 88\n",
      "Model saved to avail_station_89.pkl for station 89\n",
      "Model saved to avail_station_90.pkl for station 90\n",
      "Model saved to avail_station_91.pkl for station 91\n",
      "Model saved to avail_station_92.pkl for station 92\n",
      "Model saved to avail_station_93.pkl for station 93\n",
      "Model saved to avail_station_94.pkl for station 94\n",
      "Model saved to avail_station_95.pkl for station 95\n",
      "Model saved to avail_station_96.pkl for station 96\n",
      "Model saved to avail_station_97.pkl for station 97\n",
      "Model saved to avail_station_98.pkl for station 98\n",
      "Model saved to avail_station_99.pkl for station 99\n",
      "Model saved to avail_station_100.pkl for station 100\n",
      "Model saved to avail_station_101.pkl for station 101\n",
      "Model saved to avail_station_102.pkl for station 102\n",
      "Model saved to avail_station_103.pkl for station 103\n",
      "Model saved to avail_station_104.pkl for station 104\n",
      "Model saved to avail_station_105.pkl for station 105\n",
      "Model saved to avail_station_106.pkl for station 106\n",
      "Model saved to avail_station_107.pkl for station 107\n",
      "Model saved to avail_station_108.pkl for station 108\n",
      "Model saved to avail_station_109.pkl for station 109\n",
      "Model saved to avail_station_110.pkl for station 110\n",
      "Model saved to avail_station_111.pkl for station 111\n",
      "Model saved to avail_station_112.pkl for station 112\n",
      "Model saved to avail_station_113.pkl for station 113\n",
      "Model saved to avail_station_114.pkl for station 114\n",
      "Model saved to avail_station_115.pkl for station 115\n",
      "Model saved to avail_station_116.pkl for station 116\n",
      "Model saved to avail_station_117.pkl for station 117\n"
     ]
    }
   ],
   "source": [
    "for id in unique_ids:\n",
    "    # capacity = data[data[\"station_id\"] == id][\"capacity\"].iloc[0]\n",
    "    id_data = data[data[\"station_id\"] == id]\n",
    "    X = id_data[[\"is_weekday\", \"hour\", \"temperature\", \"humidity\", \"pressure\"]]\n",
    "    y = id_data[\"num_bikes_available\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "    model_filename = f\"avail_station_{id}.pkl\"\n",
    "    with open(model_filename, \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    print(f\"Model saved to {model_filename} for station {id}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
